{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from skmultiflow.trees import HoeffdingTree\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "fake_news = \"D:/Desktop/Fake_News_Dataset/ISOT_fake.csv\"\n",
    "true_news = \"D:/Desktop/Fake_News_Dataset/ISOT_true.csv\"\n",
    "true_df = pd.read_csv(fake_news)\n",
    "fake_df = pd.read_csv(true_news)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "true_df[\"label\"] = 1  # 1 for true news\n",
    "fake_df[\"label\"] = 0  # 0 for fake news"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine datasets\n",
    "combined_df = pd.concat([true_df, fake_df], ignore_index=True)\n",
    "\n",
    "# Shuffle data\n",
    "combined_df = combined_df.sample(frac=1, random_state=42).reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Kartik Gounder\\Desktop\\Projects\\.venv\\Lib\\site-packages\\skmultiflow\\trees\\hoeffding_tree.py:32: FutureWarning: 'HoeffdingTree' has been renamed to 'HoeffdingTreeClassifier' in v0.5.0.\n",
      "The old name will be removed in v0.7.0\n",
      "  warnings.warn(\"'HoeffdingTree' has been renamed to 'HoeffdingTreeClassifier' in v0.5.0.\\n\"\n"
     ]
    }
   ],
   "source": [
    "# Initialize TF-IDF vectorizer\n",
    "vectorizer = TfidfVectorizer(stop_words='english', max_features=5000)\n",
    "vectorizer.fit(combined_df['text'])\n",
    "# Initialize Hoeffding Tree classifier\n",
    "ht = HoeffdingTree()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Kartik Gounder\\Desktop\\Projects\\.venv\\Lib\\site-packages\\skmultiflow\\bayes\\utils.py:39: RuntimeWarning: overflow encountered in scalar multiply\n",
      "  tmp = votes[class_index] * obs.probability_of_attribute_value_given_class(\n",
      "c:\\Users\\Kartik Gounder\\Desktop\\Projects\\.venv\\Lib\\site-packages\\skmultiflow\\bayes\\utils.py:39: RuntimeWarning: invalid value encountered in scalar multiply\n",
      "  tmp = votes[class_index] * obs.probability_of_attribute_value_given_class(\n"
     ]
    }
   ],
   "source": [
    "# Incremental training\n",
    "for i in range(len(combined_df)):\n",
    "    text = combined_df.loc[i, 'text']\n",
    "    label = combined_df.loc[i, 'label']\n",
    "    \n",
    "    # Vectorize the text\n",
    "    X_partial = vectorizer.transform([text]).toarray()[0]\n",
    "    \n",
    "    # Train the Hoeffding Tree incrementally\n",
    "    ht.partial_fit([X_partial], [int(label)])  # Convert label to integer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true = combined_df['label']\n",
    "X_test = combined_df['text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train1, X_test1, y_train1, y_test1 = train_test_split(combined_df['text'], combined_df['label'], test_size = 0.2, random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Incremental model accuracy: 0.9839859236491603\n"
     ]
    }
   ],
   "source": [
    "# Convert sparse matrix to dense array\n",
    "X_test_dense = X_test.toarray()\n",
    "\n",
    "# Predict using the Hoeffding Tree classifier\n",
    "y_pred_incremental = ht.predict(X_test_dense)\n",
    "\n",
    "# Calculate accuracy\n",
    "incremental_accuracy = accuracy_score(y_true, y_pred_incremental)\n",
    "print(\"Incremental model accuracy:\", incremental_accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'HoeffdingTreeClassifier' object has no attribute 'get_model_state'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[20], line 4\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpickle\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# Get the model's state dictionary\u001b[39;00m\n\u001b[1;32m----> 4\u001b[0m model_state \u001b[38;5;241m=\u001b[39m \u001b[43mht\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_model_state\u001b[49m()\n\u001b[0;32m      6\u001b[0m \u001b[38;5;66;03m# Save the model's state to a file\u001b[39;00m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhoeffding_tree_model.pkl\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mwb\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m file:\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'HoeffdingTreeClassifier' object has no attribute 'get_model_state'"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "# Get the model's state dictionary\n",
    "model_state = ht.get_model_state()\n",
    "\n",
    "# Save the model's state to a file\n",
    "with open('hoeffding_tree_model.pkl', 'wb') as file:\n",
    "    pickle.dump(model_state, file)\n",
    "\n",
    "# Load the model's state from the file\n",
    "with open('hoeffding_tree_model.pkl', 'rb') as file:\n",
    "    loaded_model_state = pickle.load(file)\n",
    "\n",
    "# Reconstruct the model\n",
    "loaded_ht = HoeffdingTree()\n",
    "loaded_ht.set_model_state(loaded_model_state)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "PicklingError",
     "evalue": "Can't pickle <class 'skmultiflow.trees.hoeffding_tree.HoeffdingTreeClassifier'>: it's not found as skmultiflow.trees.hoeffding_tree.HoeffdingTreeClassifier",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mPicklingError\u001b[0m                             Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[18], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mdump\u001b[49m\u001b[43m(\u001b[49m\u001b[43mht\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mhoeffding_tree_model.joblib\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Kartik Gounder\\Desktop\\Projects\\.venv\\Lib\\site-packages\\joblib\\numpy_pickle.py:553\u001b[0m, in \u001b[0;36mdump\u001b[1;34m(value, filename, compress, protocol, cache_size)\u001b[0m\n\u001b[0;32m    551\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m is_filename:\n\u001b[0;32m    552\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(filename, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mwb\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[1;32m--> 553\u001b[0m         \u001b[43mNumpyPickler\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprotocol\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprotocol\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdump\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    554\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    555\u001b[0m     NumpyPickler(filename, protocol\u001b[38;5;241m=\u001b[39mprotocol)\u001b[38;5;241m.\u001b[39mdump(value)\n",
      "File \u001b[1;32mc:\\Users\\Kartik Gounder\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\pickle.py:487\u001b[0m, in \u001b[0;36m_Pickler.dump\u001b[1;34m(self, obj)\u001b[0m\n\u001b[0;32m    485\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mproto \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m4\u001b[39m:\n\u001b[0;32m    486\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mframer\u001b[38;5;241m.\u001b[39mstart_framing()\n\u001b[1;32m--> 487\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msave\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    488\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwrite(STOP)\n\u001b[0;32m    489\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mframer\u001b[38;5;241m.\u001b[39mend_framing()\n",
      "File \u001b[1;32mc:\\Users\\Kartik Gounder\\Desktop\\Projects\\.venv\\Lib\\site-packages\\joblib\\numpy_pickle.py:355\u001b[0m, in \u001b[0;36mNumpyPickler.save\u001b[1;34m(self, obj)\u001b[0m\n\u001b[0;32m    352\u001b[0m     wrapper\u001b[38;5;241m.\u001b[39mwrite_array(obj, \u001b[38;5;28mself\u001b[39m)\n\u001b[0;32m    353\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[1;32m--> 355\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mPickler\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msave\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mobj\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Kartik Gounder\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\pickle.py:603\u001b[0m, in \u001b[0;36m_Pickler.save\u001b[1;34m(self, obj, save_persistent_id)\u001b[0m\n\u001b[0;32m    599\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m PicklingError(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTuple returned by \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m must have \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    600\u001b[0m                         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtwo to six elements\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m reduce)\n\u001b[0;32m    602\u001b[0m \u001b[38;5;66;03m# Save the reduce() output and finally memoize the object\u001b[39;00m\n\u001b[1;32m--> 603\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msave_reduce\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mrv\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Kartik Gounder\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\pickle.py:687\u001b[0m, in \u001b[0;36m_Pickler.save_reduce\u001b[1;34m(self, func, args, state, listitems, dictitems, state_setter, obj)\u001b[0m\n\u001b[0;32m    684\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m PicklingError(\n\u001b[0;32m    685\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124margs[0] from __newobj__ args has the wrong class\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    686\u001b[0m args \u001b[38;5;241m=\u001b[39m args[\u001b[38;5;241m1\u001b[39m:]\n\u001b[1;32m--> 687\u001b[0m \u001b[43msave\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    688\u001b[0m save(args)\n\u001b[0;32m    689\u001b[0m write(NEWOBJ)\n",
      "File \u001b[1;32mc:\\Users\\Kartik Gounder\\Desktop\\Projects\\.venv\\Lib\\site-packages\\joblib\\numpy_pickle.py:355\u001b[0m, in \u001b[0;36mNumpyPickler.save\u001b[1;34m(self, obj)\u001b[0m\n\u001b[0;32m    352\u001b[0m     wrapper\u001b[38;5;241m.\u001b[39mwrite_array(obj, \u001b[38;5;28mself\u001b[39m)\n\u001b[0;32m    353\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[1;32m--> 355\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mPickler\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msave\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mobj\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Kartik Gounder\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\pickle.py:572\u001b[0m, in \u001b[0;36m_Pickler.save\u001b[1;34m(self, obj, save_persistent_id)\u001b[0m\n\u001b[0;32m    568\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    569\u001b[0m     \u001b[38;5;66;03m# Check for a class with a custom metaclass; treat as regular\u001b[39;00m\n\u001b[0;32m    570\u001b[0m     \u001b[38;5;66;03m# class\u001b[39;00m\n\u001b[0;32m    571\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28missubclass\u001b[39m(t, \u001b[38;5;28mtype\u001b[39m):\n\u001b[1;32m--> 572\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msave_global\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    573\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[0;32m    575\u001b[0m     \u001b[38;5;66;03m# Check for a __reduce_ex__ method, fall back to __reduce__\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Kartik Gounder\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\pickle.py:1071\u001b[0m, in \u001b[0;36m_Pickler.save_global\u001b[1;34m(self, obj, name)\u001b[0m\n\u001b[0;32m   1069\u001b[0m     obj2, parent \u001b[38;5;241m=\u001b[39m _getattribute(module, name)\n\u001b[0;32m   1070\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mImportError\u001b[39;00m, \u001b[38;5;167;01mKeyError\u001b[39;00m, \u001b[38;5;167;01mAttributeError\u001b[39;00m):\n\u001b[1;32m-> 1071\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m PicklingError(\n\u001b[0;32m   1072\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCan\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt pickle \u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m: it\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124ms not found as \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m\n\u001b[0;32m   1073\u001b[0m         (obj, module_name, name)) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1074\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1075\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m obj2 \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m obj:\n",
      "\u001b[1;31mPicklingError\u001b[0m: Can't pickle <class 'skmultiflow.trees.hoeffding_tree.HoeffdingTreeClassifier'>: it's not found as skmultiflow.trees.hoeffding_tree.HoeffdingTreeClassifier"
     ]
    }
   ],
   "source": [
    "dump(ht, 'hoeffding_tree_model.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
