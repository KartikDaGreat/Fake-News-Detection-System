{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Kartik Gounder\\Desktop\\Projects\\.venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\Kartik Gounder\\Desktop\\Projects\\.venv\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, precision_score, recall_score\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from skmultiflow.trees import HoeffdingTree\n",
    "from transformers import RobertaTokenizer, TFRobertaForSequenceClassification\n",
    "import numpy as np\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "fake_news = \"C:/Users/Kartik Gounder/Desktop/Projects/Fake News Origin Detector/Fake News Detection/Dataset/archive (2)/Fake.csv\"\n",
    "true_news = \"C:/Users/Kartik Gounder/Desktop/Projects/Fake News Origin Detector/Fake News Detection/Dataset/archive (2)/True.csv\"\n",
    "true_df = pd.read_csv(fake_news)\n",
    "fake_df = pd.read_csv(true_news)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "true_df[\"label\"] = 1  # 1 for true news\n",
    "fake_df[\"label\"] = 0  # 0 for fake news\n",
    "combined_df = pd.concat([true_df, fake_df], ignore_index=True)\n",
    "combined_df = combined_df.sample(frac=1, random_state=43).reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(combined_df['text'], combined_df['label'], test_size=0.2, random_state=43)\n",
    "\n",
    "# Initialize TF-IDF vectorizer\n",
    "vectorizer = TfidfVectorizer(stop_words='english', max_features=5000)\n",
    "X_train_tfidf = vectorizer.fit_transform(X_train)\n",
    "X_test_tfidf = vectorizer.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\Kartik Gounder\\Desktop\\Projects\\.venv\\Lib\\site-packages\\keras\\src\\backend.py:873: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFRobertaForSequenceClassification: ['roberta.embeddings.position_ids']\n",
      "- This IS expected if you are initializing TFRobertaForSequenceClassification from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFRobertaForSequenceClassification from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights or buffers of the TF 2.0 model TFRobertaForSequenceClassification were not initialized from the PyTorch model and are newly initialized: ['classifier.dense.weight', 'classifier.dense.bias', 'classifier.out_proj.weight', 'classifier.out_proj.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "tokenizer = RobertaTokenizer.from_pretrained('roberta-base')\n",
    "model = TFRobertaForSequenceClassification.from_pretrained('roberta-base', num_labels=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenize and prepare data for RoBERTa\n",
    "X_train_tokens = tokenizer(list(X_train), return_tensors='tf', padding=True, truncation=True, max_length=512)\n",
    "X_test_tokens = tokenizer(list(X_test), return_tensors='tf', padding=True, truncation=True, max_length=512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "WARNING:tensorflow:From c:\\Users\\Kartik Gounder\\Desktop\\Projects\\.venv\\Lib\\site-packages\\keras\\src\\utils\\tf_utils.py:492: The name tf.ragged.RaggedTensorValue is deprecated. Please use tf.compat.v1.ragged.RaggedTensorValue instead.\n",
      "\n",
      "WARNING:tensorflow:From c:\\Users\\Kartik Gounder\\Desktop\\Projects\\.venv\\Lib\\site-packages\\keras\\src\\engine\\base_layer_utils.py:384: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "\n",
      "   6/2245 [..............................] - ETA: 104:40:42 - loss: 0.7092 - accuracy: 0.4896"
     ]
    }
   ],
   "source": [
    "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=2e-5),\n",
    "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy'])\n",
    "model.fit(X_train_tokens['input_ids'], y_train, epochs=3, batch_size=16)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "roberta_pred_logits = model.predict(X_test_tokens['input_ids']).logits\n",
    "roberta_pred = np.argmax(roberta_pred_logits, axis=1)\n",
    "\n",
    "# Train SGD Classifier\n",
    "sgd = SGDClassifier(loss='log_loss', random_state=42)\n",
    "sgd.fit(X_train_tfidf, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ht = HoeffdingTree()\n",
    "for i in range(len(combined_df)):\n",
    "    text = combined_df.loc[i, 'text']\n",
    "    label = combined_df.loc[i, 'label']\n",
    "    X_partial = vectorizer.transform([text]).toarray()[0]\n",
    "    ht.partial_fit([X_partial], [int(label)])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sgd_pred = sgd.predict(X_test_tfidf)\n",
    "ht_pred = ht.predict(X_test_tfidf.toarray())\n",
    "\n",
    "# Concatenate predictions as features for Gradient Boosting Classifier\n",
    "X_test_features = pd.DataFrame({'RoBERTa': roberta_pred, 'SGD': sgd_pred, 'HT': ht_pred})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "roberta_metrics = [accuracy_score(y_test, roberta_pred), precision_score(y_test, roberta_pred), recall_score(y_test, roberta_pred)]\n",
    "sgd_metrics = [accuracy_score(y_test, sgd_pred), precision_score(y_test, sgd_pred), recall_score(y_test, sgd_pred)]\n",
    "ht_metrics = [accuracy_score(y_test, ht_pred), precision_score(y_test, ht_pred), recall_score(y_test, ht_pred)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to numpy arrays for statistical tests\n",
    "roberta_metrics = np.array(roberta_metrics)\n",
    "sgd_metrics = np.array(sgd_metrics)\n",
    "ht_metrics = np.array(ht_metrics)\n",
    "\n",
    "# Mann-Whitney U Test (comparing RoBERTa and SGD)\n",
    "u_stat, u_p_value = mannwhitneyu(roberta_metrics, sgd_metrics)\n",
    "print(f\"Mann-Whitney U Test between RoBERTa and SGD: U-statistic={u_stat}, p-value={u_p_value}\")\n",
    "\n",
    "# Kruskal-Wallis Test (comparing RoBERTa, SGD, and HT)\n",
    "kruskal_stat, kruskal_p_value = kruskal(roberta_metrics, sgd_metrics, ht_metrics)\n",
    "print(f\"Kruskal-Wallis Test for RoBERTa, SGD, HT: K-statistic={kruskal_stat}, p-value={kruskal_p_value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
